{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe20127-4a74-4761-8e59-d88152343e19",
   "metadata": {},
   "source": [
    "### IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee3e77f-971a-40e6-9c69-5fa3c298f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import time\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d78c2-79c5-4e36-9d0a-fb98a4fda992",
   "metadata": {},
   "source": [
    "### INITIALIZE POSE DETECTION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc79c12-378c-431f-8b6f-c56f8ed85ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INITIALIZE MEDIAPIPE POSE CLASS\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "#SETTING UP POSE FUNCTION\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence = 0.3, model_complexity=2)\n",
    "\n",
    "#INITIALIZING MEDIAPIPE DRAWING CLASS, USEFUL FOR ANNOTATION\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7012a1df-d3ff-4b05-8708-345b9f53eb7f",
   "metadata": {},
   "source": [
    "# POSE DETECTION ON AN IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c61532b7-85f9-460f-aa3d-1365339951e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#Read an image from the specific path\\nsample_img =cv2.imread(\\'images/image1.jpg\\')\\n\\n#Specify a size of the figure\\nplt.figure(figsize = [10,10])\\n\\n#Display the sample image, also convert BGR to RGB for display\\nplt.title(\"Sample Image\");plt.axis(\\'off\\');plt.imshow(sample_img[:,:,::-1]);plt.show()\\n\\n\\n#Perform pose detection after converting the image into RGB format\\nresults = pose.process(cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB))\\n\\n#Check if any landmarks are found\\nif results.pose_landmarks:\\n    \\n    #Iterate two times as we only want to display first two landmarks\\n    for i in range(2):\\n        \\n        #Display the found normalized landmarks\\n        print(f\\'{mp_pose.PoseLandmark(i).name}:\\n{results.pose_landmark[mp_pose.PoseLandmark(i).value]}\\')\\n\\n\\n\\n#Create a copy of the sample image to draw lanmarks om\\nimg_copy = sample_img.copy()\\n\\n#Check if any landmarks are found \\nif reults.pose_landmarks:\\n\\n    #Draw pose landmarks on the sample image\\n    mp_drawing.draw_landmarks(image=img_copy, landmarks_list=results.pose_landmarks, connections=mp._pose.POSE_CONNECTIONS)\\n    \\n    #Specify a size of the figure\\n    fig=plt.figure(figsize=[10,10])\\n    \\n    #Display the output image with the landmarks drawn, also convert BGR to RGB for display\\n    plt.title(\"Output\");plt.axis(\\'off\\');plt.imshow(sample_img[:,:,::-1]);plt.show()\\n    \\n\\n    \\n\\n#Plot pose landmarks in 3D\\nmp_drawing.plot_landmarks(results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\\n\\n\\n#Read another sample image and perform pose detection on it\\nimage = cv2.imread(\\'images/image1.jpg\\')\\ndetectPose(image, pose, display = True)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "#Read an image from the specific path\n",
    "sample_img =cv2.imread('images/image1.jpg')\n",
    "\n",
    "#Specify a size of the figure\n",
    "plt.figure(figsize = [10,10])\n",
    "\n",
    "#Display the sample image, also convert BGR to RGB for display\n",
    "plt.title(\"Sample Image\");plt.axis('off');plt.imshow(sample_img[:,:,::-1]);plt.show()\n",
    "\n",
    "\n",
    "#Perform pose detection after converting the image into RGB format\n",
    "results = pose.process(cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "#Check if any landmarks are found\n",
    "if results.pose_landmarks:\n",
    "    \n",
    "    #Iterate two times as we only want to display first two landmarks\n",
    "    for i in range(2):\n",
    "        \n",
    "        #Display the found normalized landmarks\n",
    "        print(f'{mp_pose.PoseLandmark(i).name}:\\n{results.pose_landmark[mp_pose.PoseLandmark(i).value]}')\n",
    "\n",
    "\n",
    "\n",
    "#Create a copy of the sample image to draw lanmarks om\n",
    "img_copy = sample_img.copy()\n",
    "\n",
    "#Check if any landmarks are found \n",
    "if reults.pose_landmarks:\n",
    "\n",
    "    #Draw pose landmarks on the sample image\n",
    "    mp_drawing.draw_landmarks(image=img_copy, landmarks_list=results.pose_landmarks, connections=mp._pose.POSE_CONNECTIONS)\n",
    "    \n",
    "    #Specify a size of the figure\n",
    "    fig=plt.figure(figsize=[10,10])\n",
    "    \n",
    "    #Display the output image with the landmarks drawn, also convert BGR to RGB for display\n",
    "    plt.title(\"Output\");plt.axis('off');plt.imshow(sample_img[:,:,::-1]);plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#Plot pose landmarks in 3D\n",
    "mp_drawing.plot_landmarks(results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "\n",
    "#Read another sample image and perform pose detection on it\n",
    "image = cv2.imread('images/image1.jpg')\n",
    "detectPose(image, pose, display = True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0354f1-83e7-4f51-959e-597ab427396c",
   "metadata": {},
   "source": [
    "# REAL TIME POSE DETECTION MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bf67e1-7ca0-4c0f-8964-1be811528204",
   "metadata": {},
   "source": [
    "### CREATE A POSE DETECTION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e12dc786-9ddb-450a-86f6-9e3cbe9267a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectPose(image, pose, display = True):\n",
    "    ''' This performs pose detection for image\n",
    "    image: input image with a person\n",
    "    pose: the pose setup function req to perform the pose detection\n",
    "    display: a boolean value that is if set to true the function displays the original input image, the resultant image, and the pose landmarks in 3D plat and returns nothing.\n",
    "\n",
    "    output_image: The input image with the detected pose landmarks drawn\n",
    "    landmarks: A list of detected landmarks converted into their original scale.\n",
    "    '''\n",
    "    #Create a copy of the input image\n",
    "    output_image = image.copy()\n",
    "    \n",
    "    #Convert the image from BGR into RGB format\n",
    "    imageRGB=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #Perform the Pose Detection\n",
    "    results=pose.process(imageRGB)\n",
    "    \n",
    "    #Retrive the height and width of the input image\n",
    "    height, width, _=image.shape\n",
    "    \n",
    "    #Initilize a list to store the detected landmarks\n",
    "    landmarks =[]\n",
    "    \n",
    "    #Check if any landmarks are detected\n",
    "    if results.pose_landmarks:\n",
    "\n",
    "        \n",
    "        #draw pose landmarks on the output image\n",
    "        mp_drawing.draw_landmarks(image=output_image, landmark_list=results.pose_landmarks, connections=mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "        #iterate over the detected landmarks\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            \n",
    "            #Append the landmarks into the list\n",
    "            landmarks.append((int(landmark.x*width), int(landmark.y*height), (landmark.z*width)))\n",
    "\n",
    "    #Check if the original input image and the resultant image are specified to be displayed\n",
    "    if display:    \n",
    "\n",
    "        #Display the original input image and the resultant image\n",
    "        plt.figure(figsize=[22,22])\n",
    "        plt.subplot(121);plt.imshow(image[:,:,::-1]);plt.title(\"Original Image\");plt.axis('off');\n",
    "        plt.subplot(122);plt.imshow(output_image[:,:,::-1]);plt.title(\"Original Image\");plt.axis('off');\n",
    "        \n",
    "        #Also Plot the pose landmarks in 3D\n",
    "        mp_drawing.plot_landmarks(results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    #Otherwise\n",
    "    else:\n",
    "\n",
    "        #Retuen the output image and the found landmarks\n",
    "        return output_image, landmarks\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83126b8-a249-4e8b-8957-62d1061cc25d",
   "metadata": {},
   "source": [
    "### POSE DETECTION ON REAL TIME WEBCAM FEED/VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c0e391f-bb4f-45a6-bd56-8dd68e55ffd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Systems\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "#Setup Pose function for video\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)\n",
    "\n",
    "#Intilize the VideoCapture object to real from the webcame\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "#Create named window for resizing purposes\n",
    "cv2.namedWindow('Pose Detection', cv2.WINDOW_NORMAL)\n",
    "\n",
    "#Intialize the videocapture object to read from a video stored in the disk\n",
    "#video = cv2.VideoCapture('media/running.mp4')\n",
    "\n",
    "#Set video camera size\n",
    "video.set(3,1280)\n",
    "video.set(4,960)\n",
    "\n",
    "#Initialize a variable to store the time of the previous frame\n",
    "time1=0\n",
    "\n",
    "#interate until the video is accessed successfully\n",
    "while video.isOpened():\n",
    "\n",
    "    #Read a frame\n",
    "    ok, frame = video.read()\n",
    "\n",
    "    #check if frame is not read properly\n",
    "    if not ok:\n",
    "        \n",
    "        #break the loop\n",
    "        break\n",
    "\n",
    "    #Flip the frame horizontally for natural (selfie -view) visualization\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    #Get the width and height of the frame`\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    \n",
    "    #Resize the frame while keeping the aspect ratio\n",
    "    frame= cv2.resize(frame, (int(frame_width * (640/ frame_height)), 640))\n",
    "    \n",
    "    #Perfirm Pose Landmark detection\n",
    "    frame, _ = detectPose(frame, pose_video, display=False)\n",
    "\n",
    "    #Set time for this frame to the current time\n",
    "    time2 = time()\n",
    "    \n",
    "    #Check if the difference between the previous and this frame time > 0 to avoid division by zero\n",
    "    if (time2 - time1) > 0:\n",
    "\n",
    "        #calculate the number of frames per second\n",
    "        frames_per_second = 1.0 / (time2 - time1)\n",
    "        \n",
    "        #write the calculated nimber of frames per second on the frame\n",
    "        cv2.putText(frame, 'FPS: {}'.format(int(frames_per_second)), (10,30),cv2.FONT_HERSHEY_PLAIN, 2, (0,255,0), 3)\n",
    "\n",
    "    #Update the previos frame time to this frame time\n",
    "    #As this frame will become previous frame in next interation\n",
    "    time1=time2\n",
    "    \n",
    "    #Display the frame\n",
    "    cv2.imshow('Pose Detection', frame)\n",
    "\n",
    "    #Wait until a key is pressed\n",
    "    #Retreive the ASCII code of the key pressed\n",
    "    k=cv2.waitKey(1) & 0xff\n",
    "\n",
    "    #Check if 'Esc' is pressed\n",
    "    if (k==27):\n",
    "\n",
    "        #Break the loop\n",
    "        break\n",
    "\n",
    "#Release the VideoCapture\n",
    "video.release()\n",
    "\n",
    "#Close the windows\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ec42e-0aa5-4401-87e3-b58363735f57",
   "metadata": {},
   "source": [
    "# POSE CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c9aebd-3ca3-4483-9331-7601118147a6",
   "metadata": {},
   "source": [
    "### with angle heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fb30ed1-dabd-4d97-ae5d-704e2dcf3f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAngle(landmark1, landmark2, landmark3):\n",
    "    ''' this function calculates angle between three different landmarks\n",
    "    landmark1: the first landmark containg the x,y and z coordinates.\n",
    "    landmark2: the second landmark containg the x,y and z coordinates.\n",
    "    landmark3: the third landmark containg the x,y and z coordinates.\n",
    "    angle: the calculated dangle b/w the three landmarks '''\n",
    "    #get the req landmarks\n",
    "    x1, y1, _ = landmark1\n",
    "    x2, y2, _ = landmark2\n",
    "    x3, y3, _ = landmark3\n",
    "    #calculate the angle b/w the three points\n",
    "    angle = math.degrees(math.atan2(y3-y2, x3-x2) - math.atan2(y1-y2,x1-x2))\n",
    "    #check if the angle is less than zero\n",
    "    if angle <0:\n",
    "        #add 360 to the found angle\n",
    "        angle +=360\n",
    "    #return the calculated angle\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80714c71-4949-46b1-8bdd-0b1917cade64",
   "metadata": {},
   "source": [
    "## CREATE A FUNCTION TO PERFORM POSE CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1819bd2-dddc-4f59-95f1-717d73878840",
   "metadata": {},
   "source": [
    "### following yoga poses : Warrior II Pose, T Pose, Tree Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f53bcfe-1f3b-4b48-8c85-31f4bc118d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyPose(landmarks, output_image, display=False):\n",
    "    ''' this function classifies yoga poses depending upon the angles of various body joints\n",
    "    landmarks: a list of detected landmarks of the person whose pose needs to be classified\n",
    "    output_image: a image of the person with the detected pose landmark drawn\n",
    "    display: a boolean value that is if set to true the function displays the resultant image with the pose label written on it and returns nothing\n",
    "    output_image: the image with detected pose landmarks drawn and pose label written \n",
    "    label: the classified pose label of the person in the output_image. '''\n",
    "    \n",
    "    #initialize the label of the pose. if it is not known at this stage\n",
    "    label ='Unkown Pose'\n",
    "    #specify the color (Red) with which the label will be written on the image\n",
    "    color=(0,0,255)\n",
    "\n",
    "    #Calculate the required angles\n",
    "\n",
    "    #angle b/w left shoulder, elbow and wrist points\n",
    "    left_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "    #angle b/w right shoulder, elbow and wrist points\n",
    "    right_elbow_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])\n",
    "    #angle b/w left elbow, shoulder and hip points\n",
    "    left_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
    "    #angle b/w right hip, shoulder and elbow points\n",
    "    right_shoulder_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "    #angle b/w left hip, knee and angle points\n",
    "    left_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "    #angle b/w left hip, knee and angle points\n",
    "    right_knee_angle = calculateAngle(landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value],\n",
    "                                     landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "    \n",
    "    \n",
    "    #Check if it is the warrior II pose or T pose\n",
    "    #As for both of them, both arms should be straight and shoulders should be at the specific angle\n",
    "\n",
    "    #Check if both arms are straight\n",
    "    if left_elbow_angle > 165 and left_elbow_angle <195 and right_elbow_angle > 165 and right_elbow_angle <195:\n",
    "        #check if shoulders are at the req angle\n",
    "        if left_shoulder_angle > 80 and left_shoulder_angle <110 and right_shoulder_angle > 80 and right_shoulder_angle <110:\n",
    "    #Check if Warrior II\n",
    "            #check if one leg straight\n",
    "            if left_knee_angle >105 and left_knee_angle < 195 or right_knee_angle >105 and right_knee_angle < 195:\n",
    "                #Check if the other leg is bended at the required angle\n",
    "                if left_knee_angle >90 and left_knee_angle < 120 or right_knee_angle >90 and right_knee_angle < 120:\n",
    "                    #specify label of the pose as Warrior II\n",
    "                    label = 'Warrior II Pose'\n",
    "\n",
    "    #Check if T Pose\n",
    "            #Check if both legs are straight\n",
    "            if left_knee_angle >160 and left_knee_angle < 195 and right_knee_angle >160 and right_knee_angle < 195:\n",
    "                #specify label of the pose as Warrior II\n",
    "                    label = 'T Pose'\n",
    "\n",
    "    # Check if Tree Pose\n",
    "    # Check if one leg is straight\n",
    "    if left_knee_angle >165 and left_knee_angle < 195 or right_knee_angle >165 and right_knee_angle < 195:\n",
    "        #Check if the other leg is bended at req angle\n",
    "        if left_knee_angle >315 and left_knee_angle < 335 or right_knee_angle >25 and right_knee_angle < 45:\n",
    "            #specify label of the pose as Warrior II\n",
    "                    label = 'Tree Pose'\n",
    "\n",
    "    #Check if pose is classified successfully\n",
    "    if label != 'Unknown Pose':\n",
    "        #Update the color(to green) with the label will be written on the image\n",
    "        color = (0,255,0)\n",
    "\n",
    "    #Write the label on the output image\n",
    "    cv2.putText(output_image, label, (10,30), cv2.FONT_HERSHEY_PLAIN, 2, color, 2)\n",
    "\n",
    "    #Check if the resultant image is specifies to be displayed\n",
    "    if display:\n",
    "        #Display the resultant image\n",
    "        plt.figure(figsize=[10,10])\n",
    "        plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "\n",
    "    else:\n",
    "        #Return the output image and the classified label\n",
    "        return output_image, label\n",
    "        \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a26f496-99a1-4f41-909c-3ca91c23f2d5",
   "metadata": {},
   "source": [
    "### POSE CLASSIFICATION ON REAL TIME WEBCAM FEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b18b48ba-1c0b-49cd-9d93-14b23a2cf470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Pose function for video\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1)\n",
    "\n",
    "#Intialize the VideoCapture object to read from the webcam\n",
    "camera_video = cv2.VideoCapture(0)\n",
    "camera_video.set(3,1280)\n",
    "camera_video.set(4,960)\n",
    "\n",
    "#Initialize a resizable window\n",
    "cv2.namedWindow('Pose Classification', cv2. WINDOW_NORMAL)\n",
    "\n",
    "#Iterate until the webcam is accessed successfully.\n",
    "while camera_video.isOpened():\n",
    "    #Read a frame\n",
    "    ok, frame = camera_video.read()\n",
    "    #check if frame is not read properly\n",
    "    if not ok:\n",
    "        #continue to the next iteration to read the next frame and ignore the empty camera frame\n",
    "        continue\n",
    "    #Flip the frame horizontally for natural (selfie-view) viisualization\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    #Get the width and height of the frame\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    #Resize the frame while keeping the aspect ratio\n",
    "    frame= cv2.resize(frame, (int(frame_width * (640/ frame_height)), 640))\n",
    "    #Perform Pose Landmark detection\n",
    "    frame, landmarks = detectPose(frame, pose_video, display=False)\n",
    "\n",
    "    #Check if landmarks are detected\n",
    "    if landmarks:\n",
    "        #Perform the Pose  Classification\n",
    "        frame, _ = classifyPose(landmarks, frame, display=False)\n",
    "\n",
    "    #Display the frame\n",
    "    cv2.imshow('Pose Classification', frame)\n",
    "\n",
    "\n",
    "    #Wait until a key is pressed\n",
    "    #Retreive the ASCII code of the key presses\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    #Check if 'ESC' is pressed\n",
    "    if (k== 27):\n",
    "        #break the line\n",
    "        break\n",
    "\n",
    "#Release the VideoCapture object and close the window\n",
    "camera_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
